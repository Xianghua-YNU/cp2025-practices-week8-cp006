# 实验二：数值微分的误差权衡

## 1. 实验目的
- 理解数值微分中截断误差与舍入误差的权衡关系
- 观察有限差分法计算导数时的误差变化规律
- 分析步长对数值微分精度的影响
- 确定最优步长范围

## 2. 实验方法
### 2.1 理论基础
数值微分是通过有限差分近似导数的计算方法。本实验实现了两种差分方法：
- 前向差分法: $f'(x) \approx \frac{f(x+\delta) - f(x)}{\delta}$
- 中心差分法: $f'(x) \approx \frac{f(x+\delta) - f(x-\delta)}{2\delta}$

### 2.2 测试函数
本实验使用函数 $f(x) = x(x-1)$，其解析导数为 $f'(x) = 2x - 1$。

### 2.3 实验步骤
1. 实现前向差分和中心差分函数
2. 在 $x=1$ 点计算不同步长下的数值导数
3. 计算数值导数与解析导数的相对误差
4. 绘制误差-步长关系图（对数坐标）
5. 分析最优步长和收敛阶数

## 3. 实验结果
### 3.1 数据表格
| 步长(δ) | 前向差分值 | 中心差分值 | 解析解 | 前向差分相对误差 | 中心差分相对误差 |
--------------------------------------------------------------------------------
| 1.00e-14 | 9.992007e-01 | 9.992007e-01 | 1.000000e+00 | 7.992778e-04 | 7.992778e-04 |
| 1.00e-13 | 9.992007e-01 | 9.997558e-01 | 1.000000e+00 | 7.992778e-04 | 2.441663e-04 |
| 1.00e-12 | 1.000089e+00 | 1.000033e+00 | 1.000000e+00 | 8.890058e-05 | 3.338943e-05 |
| 1.00e-11 | 1.000000e+00 | 1.000000e+00 | 1.000000e+00 | 8.275037e-08 | 8.274037e-08 |
| 1.00e-10 | 1.000000e+00 | 1.000000e+00 | 1.000000e+00 | 8.284037e-08 | 8.274037e-08 |
| 1.00e-09 | 1.000000e+00 | 1.000000e+00 | 1.000000e+00 | 8.374037e-08 | 2.722922e-08 |
| 1.00e-08 | 1.000000e+00 | 1.000000e+00 | 1.000000e+00 | 3.922529e-09 | 5.263561e-10 |
| 1.00e-07 | 1.000000e+00 | 1.000000e+00 | 1.000000e+00 | 1.005839e-07 | 2.875589e-11 |
| 1.00e-06 | 1.000001e+00 | 1.000000e+00 | 1.000000e+00 | 9.999177e-07 | 2.675549e-11 |
| 1.00e-05 | 1.000010e+00 | 1.000000e+00 | 1.000000e+00 | 1.000001e-05 | 1.000089e-12 |
| 1.00e-04 | 1.000100e+00 | 1.000000e+00 | 1.000000e+00 | 1.000000e-04 | 1.101341e-13 |
| 1.00e-03 | 1.001000e+00 | 1.000000e+00 | 1.000000e+00 | 1.000000e-03 | 5.462297e-14 |
| 1.00e-02 | 1.010000e+00 | 1.000000e+00 | 1.000000e+00 | 1.000000e-02 | 8.881784e-16 |

### 3.2 误差-步长关系图
（在此插入误差-步长关系图，并简要说明图中观察到的现象）![c7111bd09230a832553a84786c79c72](https://github.com/user-attachments/assets/3634341a-de4a-4265-872d-d9372d22448e)
前向差分误差随步长减小先降后升，对数坐标下近似线性，斜率为负，呈一阶收敛特性；
中心差分误差下降更快，与二阶误差线近似，精度更高，但步长过小时也受舍入误差影响；
参考线可直观验证前向差分一阶收敛、中心差分二阶收敛 。


## 4. 分析与讨论
### 4.1 误差来源分析
数值微分中存在两种主要误差来源：
- **截断误差**：由于使用有限差分近似导数定义引入的误差，通常随步长减小而减小
- **舍入误差**：由于计算机浮点数表示的有限精度引入的误差，通常随步长减小而增大

（分析实验中观察到的截断误差和舍入误差的表现）从误差 - 步长图中可看到，随着步长减小，相对误差减小，这表明截断误差随步长减小而降低。而当步长过小，舍入误差占主导，继续减小步长，相对误差反而增大，这是因为计算机浮点数表示精度有限，在进行数值计算时会产生舍入误差。

### 4.2 前向差分与中心差分的比较
（比较两种方法的精度差异，并解释原因）中心差分法精度更高。从结果可知，中心差分的相对误差整体小于前向差分。这是因为前向差分公式是一阶精度；而中心差分公式是二阶精度。在相同步长下，中心差分能更精确地逼近导数的真实值。

### 4.3 最优步长分析
（分析实验中观察到的最优步长，并解释为什么存在最优步长）实验中每种方法都存在最优步长。对于前向差分和中心差分，当步长为最优值时，相对误差最小。这是因为截断误差和舍入误差随步长变化的趋势相反。步长较大时，截断误差大；步长较小时，舍入误差大。最优步长就是截断误差和舍入误差之和最小的点。

### 4.4 收敛阶数分析
（分析两种方法的收敛阶数，并与理论预期进行比较）前向差分收敛阶数约为 1，中心差分收敛阶数约为 2，这与理论预期相符。前向差分理论上是一阶收敛，中心差分理论上是二阶收敛。这表明在中间区域，两种方法的误差收敛特性和理论推导一致。

## 5. 实验结论
（总结本实验的主要发现，特别是关于误差权衡、最优步长和不同差分方法的优缺点）误差权衡：数值微分中截断误差和舍入误差相互制约，需选取合适步长以平衡两种误差。
最优步长：存在最优步长使误差最小，这是两种误差综合作用的结果。
差分方法优缺点：前向差分计算简单，但精度低；中心差分精度高，但计算量稍大，需要计算两个点的函数值。

## 附录：核心代码片段
```python
# 前向差分法实现
def forward_diff(f, x, delta):
    return (f(x + delta) - f(x)) / delta

# 中心差分法实现
def central_diff(f, x, delta):
    return (f(x + delta) - f(x - delta)) / (2 * delta)

# 计算误差的代码
def calculate_errors(x_point=1.0):
    """计算不同步长下的误差"""
    # 步长序列
    deltas = np.logspace(-14, -2, 13)

    # 解析解
    true_value = analytical_derivative(x_point)

    # 存储结果
    forward_errors = []
    central_errors = []

    # 计算不同步长下的误差
    for delta in deltas:
        # 前向差分
        forward_value = forward_diff(f, x_point, delta)
        forward_rel_error = abs((forward_value - true_value) / true_value)
        forward_errors.append(forward_rel_error)

        # 中心差分
        central_value = central_diff(f, x_point, delta)
        central_rel_error = abs((central_value - true_value) / true_value)
        central_errors.append(central_rel_error)

    return deltas, forward_errors, central_errors
# ...

# 绘制误差-步长关系图的代码

#def plot_errors(deltas, forward_errors, central_errors):
    """绘制误差-步长关系图"""
    plt.figure(figsize=(10, 6))

    # 绘制前向差分误差
    plt.loglog(deltas, forward_errors, 'o-', label='Forward Difference')

    # 绘制中心差分误差
    plt.loglog(deltas, central_errors, 's-', label='Central Difference')

    # 添加参考线
    plt.loglog(deltas, deltas, '--', label='First Order O(h)')
    plt.loglog(deltas, np.array(deltas) ** 2, '--', label='Second Order O($h^2$)')

    # 设置图表
    plt.xlabel('Step Size $\\delta$')  # Fixed escape sequence
    plt.ylabel('Relative Error')
    plt.title('Error vs Step Size in Numerical Differentiation')
    plt.grid(True, which="both", ls="-")
    plt.legend()

    # 保存图表
    plt.savefig('error_vs_stepsize.png', dpi=300)
    plt.show() ...
```
